{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIoybzivUgqk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "5f2201e7-3b13-4c4b-b95b-4c800e54d284"
      },
      "source": [
        "'''环境准备'''\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "'''挂载google硬盘'''\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "\n",
        "'''导入文件'''\n",
        "from drive import *"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 144465 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.22-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.22-0ubuntu3~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.22-0ubuntu3~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGSbXF8DUsK2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb1f1c5f-17a5-4813-ca14-2bd12047ae6d"
      },
      "source": [
        "##########################################################  auto_arima ############################################################\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns #热力图\n",
        "import itertools \n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm \n",
        "from statsmodels.tsa.stattools import adfuller #ADF检验\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox #白噪声检验\n",
        "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf #画图定阶\n",
        "from statsmodels.tsa.arima_model import ARIMA #模型\n",
        "from statsmodels.tsa.arima_model import ARMA #模型\n",
        "from statsmodels.stats.stattools import durbin_watson #DW检验\n",
        "from statsmodels.graphics.api import qqplot #qq图\n",
        "\n",
        "#导入数据\n",
        "data = pd.read_csv('/content/drive/jupyter/data/examples/example_wp_log_peyton_manning.csv', usecols=[1])\n",
        "\n",
        "train_arima = data[:int(0.8*(len(data)))]\n",
        "test_arima = data[int(0.8*(len(data))):]\n",
        "\n",
        "print('初始训练集长度:',len(train_arima))\n",
        "print('初始测试集长度:',len(test_arima))\n",
        "look_back = 5\n",
        "\n",
        "#安装包\n",
        "!pip install pyramid-arima\n",
        "\n",
        "#building the model\n",
        "from pyramid.arima import auto_arima\n",
        "model_autoarima = auto_arima(train_arima,trace=True,error_aciton='ignore',suppress_warnings=True)\n",
        "model_autoarima.fit(train_arima)\n",
        "\n",
        "pre_train_arima = model_autoarima.predict(n_periods=len(train_arima))\n",
        "pre_train_arima = pd.DataFrame(pre_train_arima,index = train_arima.index,columns=['pre_train_arima']) \n",
        "pre_test_arima = model_autoarima.predict(n_periods=len(test_arima))\n",
        "pre_test_arima = pd.DataFrame(pre_test_arima,index = test_arima.index,columns=['pre_test_arima'])\n",
        "print('pre_test_arima类型：',type(pre_test_arima))\n",
        "print('pre_test_arima:',pre_test_arima)\n",
        "\n",
        "print('训练集预测长度为:',len(pre_train_arima))\n",
        "print('测试集预测长度为:',len(pre_test_arima))\n",
        "\n",
        "#calculate rmse\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "train_arima = train_arima[look_back:len(train_arima)+1]\n",
        "test_arima = test_arima[look_back:len(test_arima)+1]\n",
        "\n",
        "print('截取的训练集长度为:',len(train_arima))\n",
        "print('截取的测试集长度为:',len(test_arima))\n",
        "\n",
        "pre_train_arima = pre_train_arima[look_back:len(train_arima)+look_back+1]\n",
        "pre_test_arima = pre_test_arima[look_back:len(test_arima)+look_back+1]\n",
        "\n",
        "print('截取的预测训练集长度为:',len(pre_train_arima))\n",
        "print('截取的预测测试集长度为:',len(pre_test_arima))\n",
        "\n",
        "train_rmse_arima = math.sqrt(mean_squared_error(train_arima,pre_train_arima)) \n",
        "test_rmse_arima = math.sqrt(mean_squared_error(test_arima,pre_test_arima))\n",
        "print('train_rmse_arima:',train_rmse_arima)\n",
        "print('test_rmse_arima:',test_rmse_arima)\n",
        "\n",
        "#plot the predictions for validation set\n",
        "plt.plot(train_arima, label='train_arima')\n",
        "plt.plot(test_arima, label='test_arima')\n",
        "plt.plot(pre_train_arima, label='pre_train_arima')\n",
        "plt.plot(pre_test_arima, label='pre_test_arima')\n",
        "plt.show()\n",
        "print(model_autoarima.summary())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "初始训练集长度: 2324\n",
            "初始测试集长度: 581\n",
            "Requirement already satisfied: pyramid-arima in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
            "Requirement already satisfied: scikit-learn>=0.17 in /usr/local/lib/python3.6/dist-packages (from pyramid-arima) (0.22.2.post1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from pyramid-arima) (0.10.2)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.6/dist-packages (from pyramid-arima) (1.0.5)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from pyramid-arima) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.6/dist-packages (from pyramid-arima) (1.18.5)\n",
            "Requirement already satisfied: Cython>=0.23 in /usr/local/lib/python3.6/dist-packages (from pyramid-arima) (0.29.21)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.17->pyramid-arima) (0.16.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels>=0.9.0->pyramid-arima) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->pyramid-arima) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->pyramid-arima) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.0->statsmodels>=0.9.0->pyramid-arima) (1.15.0)\n",
            "Fit ARIMA: order=(2, 1, 2) seasonal_order=(0, 0, 0, 1); AIC=2712.545, BIC=2747.048, Fit time=3.131 seconds\n",
            "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 0, 0, 1); AIC=3190.012, BIC=3201.513, Fit time=0.193 seconds\n",
            "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 0, 0, 1); AIC=3159.654, BIC=3176.906, Fit time=0.201 seconds\n",
            "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 0, 0, 1); AIC=3111.492, BIC=3128.744, Fit time=0.454 seconds\n",
            "Fit ARIMA: order=(1, 1, 2) seasonal_order=(0, 0, 0, 1); AIC=2732.240, BIC=2760.993, Fit time=1.403 seconds\n",
            "Fit ARIMA: order=(3, 1, 2) seasonal_order=(0, 0, 0, 1); AIC=2728.549, BIC=2768.803, Fit time=2.174 seconds\n",
            "Fit ARIMA: order=(2, 1, 1) seasonal_order=(0, 0, 0, 1); AIC=2724.550, BIC=2753.303, Fit time=1.312 seconds\n",
            "Fit ARIMA: order=(2, 1, 3) seasonal_order=(0, 0, 0, 1); AIC=2714.195, BIC=2754.449, Fit time=4.059 seconds\n",
            "Fit ARIMA: order=(1, 1, 1) seasonal_order=(0, 0, 0, 1); AIC=2796.228, BIC=2819.231, Fit time=1.244 seconds\n",
            "Fit ARIMA: order=(3, 1, 3) seasonal_order=(0, 0, 0, 1); AIC=2664.143, BIC=2710.148, Fit time=6.393 seconds\n",
            "Fit ARIMA: order=(4, 1, 3) seasonal_order=(0, 0, 0, 1); AIC=2597.593, BIC=2649.349, Fit time=6.618 seconds\n",
            "Fit ARIMA: order=(4, 1, 2) seasonal_order=(0, 0, 0, 1); AIC=2549.234, BIC=2595.238, Fit time=5.615 seconds\n",
            "Fit ARIMA: order=(3, 1, 1) seasonal_order=(0, 0, 0, 1); AIC=2725.648, BIC=2760.152, Fit time=2.100 seconds\n",
            "Fit ARIMA: order=(5, 1, 3) seasonal_order=(0, 0, 0, 1); AIC=2492.454, BIC=2549.960, Fit time=7.466 seconds\n",
            "Fit ARIMA: order=(5, 1, 2) seasonal_order=(0, 0, 0, 1); AIC=2492.780, BIC=2544.535, Fit time=4.688 seconds\n",
            "Fit ARIMA: order=(5, 1, 4) seasonal_order=(0, 0, 0, 1); AIC=2461.249, BIC=2524.506, Fit time=6.788 seconds\n",
            "Fit ARIMA: order=(4, 1, 4) seasonal_order=(0, 0, 0, 1); AIC=2542.463, BIC=2599.969, Fit time=7.677 seconds\n",
            "Fit ARIMA: order=(5, 1, 5) seasonal_order=(0, 0, 0, 1); AIC=2345.976, BIC=2414.983, Fit time=10.233 seconds\n",
            "Fit ARIMA: order=(4, 1, 5) seasonal_order=(0, 0, 0, 1); AIC=2396.931, BIC=2460.188, Fit time=9.206 seconds\n",
            "Total fit time: 80.967 seconds\n",
            "pre_test_arima类型： <class 'pandas.core.frame.DataFrame'>\n",
            "pre_test_arima:       pre_test_arima\n",
            "2324        7.372741\n",
            "2325        7.479137\n",
            "2326        7.549656\n",
            "2327        7.523144\n",
            "2328        7.388218\n",
            "...              ...\n",
            "2900        7.075529\n",
            "2901        7.075053\n",
            "2902        7.074430\n",
            "2903        7.073699\n",
            "2904        7.072982\n",
            "\n",
            "[581 rows x 1 columns]\n",
            "训练集预测长度为: 2324\n",
            "测试集预测长度为: 581\n",
            "截取的训练集长度为: 2319\n",
            "截取的测试集长度为: 576\n",
            "截取的预测训练集长度为: 2319\n",
            "截取的预测测试集长度为: 576\n",
            "train_rmse_arima: 1.7783738389747257\n",
            "test_rmse_arima: 1.0237684429245197\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y32AH3Mdu-YD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "77c9d8d8-00e3-4499-8743-b0a253fb1acd"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Statespace Model Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>   <td>2324</td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>           <td>SARIMAX(5, 1, 5)</td> <th>  Log Likelihood     </th> <td>-1160.988</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>            <td>Sat, 25 Jul 2020</td> <th>  AIC                </th> <td>2345.976</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                <td>12:58:33</td>     <th>  BIC                </th> <td>2414.983</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Sample:</th>                  <td>0</td>        <th>  HQIC               </th> <td>2371.123</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th></th>                      <td> - 2324</td>     <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>        <td>opg</td>       <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>intercept</th> <td>   -0.0006</td> <td>    0.003</td> <td>   -0.177</td> <td> 0.859</td> <td>   -0.007</td> <td>    0.006</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>ar.L1</th>     <td>    1.1869</td> <td>    0.043</td> <td>   27.299</td> <td> 0.000</td> <td>    1.102</td> <td>    1.272</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>ar.L2</th>     <td>   -1.7052</td> <td>    0.038</td> <td>  -44.350</td> <td> 0.000</td> <td>   -1.781</td> <td>   -1.630</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>ar.L3</th>     <td>    1.3073</td> <td>    0.058</td> <td>   22.412</td> <td> 0.000</td> <td>    1.193</td> <td>    1.422</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>ar.L4</th>     <td>   -1.2415</td> <td>    0.031</td> <td>  -39.551</td> <td> 0.000</td> <td>   -1.303</td> <td>   -1.180</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>ar.L5</th>     <td>    0.3953</td> <td>    0.035</td> <td>   11.428</td> <td> 0.000</td> <td>    0.327</td> <td>    0.463</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>ma.L1</th>     <td>   -1.5218</td> <td>    0.041</td> <td>  -37.020</td> <td> 0.000</td> <td>   -1.602</td> <td>   -1.441</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>ma.L2</th>     <td>    1.8318</td> <td>    0.049</td> <td>   37.086</td> <td> 0.000</td> <td>    1.735</td> <td>    1.929</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>ma.L3</th>     <td>   -1.6211</td> <td>    0.056</td> <td>  -28.704</td> <td> 0.000</td> <td>   -1.732</td> <td>   -1.510</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>ma.L4</th>     <td>    1.2624</td> <td>    0.038</td> <td>   32.844</td> <td> 0.000</td> <td>    1.187</td> <td>    1.338</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>ma.L5</th>     <td>   -0.6213</td> <td>    0.024</td> <td>  -25.604</td> <td> 0.000</td> <td>   -0.669</td> <td>   -0.574</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>sigma2</th>    <td>    0.1587</td> <td>    0.002</td> <td>   64.553</td> <td> 0.000</td> <td>    0.154</td> <td>    0.164</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Ljung-Box (Q):</th>          <td>68.19</td> <th>  Jarque-Bera (JB):  </th> <td>6515.60</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Q):</th>                <td>0.00</td>  <th>  Prob(JB):          </th>  <td>0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Heteroskedasticity (H):</th> <td>1.25</td>  <th>  Skew:              </th>  <td>1.49</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(H) (two-sided):</th>    <td>0.00</td>  <th>  Kurtosis:          </th>  <td>10.65</td> \n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Covariance matrix calculated using the outer product of gradients (complex-step)."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                           Statespace Model Results                           \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   No. Observations:                 2324\n",
              "Model:               SARIMAX(5, 1, 5)   Log Likelihood               -1160.988\n",
              "Date:                Sat, 25 Jul 2020   AIC                           2345.976\n",
              "Time:                        12:58:33   BIC                           2414.983\n",
              "Sample:                             0   HQIC                          2371.123\n",
              "                               - 2324                                         \n",
              "Covariance Type:                  opg                                         \n",
              "==============================================================================\n",
              "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "intercept     -0.0006      0.003     -0.177      0.859      -0.007       0.006\n",
              "ar.L1          1.1869      0.043     27.299      0.000       1.102       1.272\n",
              "ar.L2         -1.7052      0.038    -44.350      0.000      -1.781      -1.630\n",
              "ar.L3          1.3073      0.058     22.412      0.000       1.193       1.422\n",
              "ar.L4         -1.2415      0.031    -39.551      0.000      -1.303      -1.180\n",
              "ar.L5          0.3953      0.035     11.428      0.000       0.327       0.463\n",
              "ma.L1         -1.5218      0.041    -37.020      0.000      -1.602      -1.441\n",
              "ma.L2          1.8318      0.049     37.086      0.000       1.735       1.929\n",
              "ma.L3         -1.6211      0.056    -28.704      0.000      -1.732      -1.510\n",
              "ma.L4          1.2624      0.038     32.844      0.000       1.187       1.338\n",
              "ma.L5         -0.6213      0.024    -25.604      0.000      -0.669      -0.574\n",
              "sigma2         0.1587      0.002     64.553      0.000       0.154       0.164\n",
              "===================================================================================\n",
              "Ljung-Box (Q):                       68.19   Jarque-Bera (JB):              6515.60\n",
              "Prob(Q):                              0.00   Prob(JB):                         0.00\n",
              "Heteroskedasticity (H):               1.25   Skew:                             1.49\n",
              "Prob(H) (two-sided):                  0.00   Kurtosis:                        10.65\n",
              "===================================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkKDyJcsu-HE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWmMQw46u8pW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################################## bayes-lstm ############################################################\n",
        "!pip install bayesian-optimization\n",
        "from bayes_opt import BayesianOptimization\n",
        "# 数据不归一化，数据满足预设的训练和测试长度\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "look_back = 5\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-look_back):\n",
        "\t\ta = dataset[i:(i+look_back), 0]\n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + look_back, 0])\n",
        "\treturn np.array(dataX), np.array(dataY)\n",
        "\n",
        "def lstm_error(look_back,first_unit,second_unit,epoch,batch_size): \n",
        "\timport math\n",
        "\tlook_back = math.floor(look_back)\n",
        "\tfirst_unit = math.floor(first_unit)\n",
        "\tsecond_unit = math.floor(second_unit)\n",
        "\tepoch = math.floor(epoch)\n",
        "\tbatch_size = math.floor(batch_size)\n",
        "\t# fix random seed for reproducibility\n",
        "\tnp.random.seed(7)\n",
        "\n",
        "\t# load the dataset\n",
        "\tdataframe = pd.read_csv('/content/drive/jupyter/data/examples/example_wp_log_peyton_manning.csv', usecols=[1])\n",
        "\t# dataframe = pd.read_excel('/content/drive/jupyter/data/swat/All.xlsx', usecols=[2])\n",
        "\n",
        "\tdataset = dataframe.values\n",
        "\tdataset = dataset.astype('float32')\n",
        "\n",
        "\t# split into train and test sets\n",
        "\ttrain_size = int(len(dataset) * 0.8)\n",
        "\ttest_size = len(dataset) - train_size\n",
        "\ttrain_lstm, test_lstm = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "\n",
        "\t# reshape into X=t and Y=t+1\n",
        "\tx_train_lstm, y_train_lstm = create_dataset(train_lstm, look_back)\n",
        "\tx_test_lstm, y_test_lstm = create_dataset(test_lstm, look_back)\n",
        "\n",
        "\t# reshape input to be [samples, time steps, features]\n",
        "\tx_train_lstm = np.reshape(x_train_lstm, (x_train_lstm.shape[0], x_train_lstm.shape[1], 1))\n",
        "\tx_test_lstm = np.reshape(x_test_lstm, (x_test_lstm.shape[0], x_test_lstm.shape[1], 1))\n",
        "\n",
        "\t# print('y_test_lstm:',y_test_lstm)\n",
        "\t# print('type(y_test_lstm):',type(y_test_lstm))\n",
        "\n",
        "\t# create and fit the LSTM network\n",
        "\tmodel_lstm = Sequential()\n",
        "\tmodel_lstm.add(LSTM(first_unit, activation='relu',return_sequences=True,input_shape=(x_train_lstm.shape[1], x_train_lstm.shape[2])))\n",
        "\tmodel_lstm.add(LSTM(second_unit, activation='relu'))\n",
        "\tmodel_lstm.add(Dense(1))\n",
        "\tmodel_lstm.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\tmodel_lstm.fit(x_train_lstm, y_train_lstm, nb_epoch=epoch, batch_size=batch_size, verbose=0)\n",
        "\n",
        "\t# make predictions\n",
        "\tpre_train_lstm = model_lstm.predict(x_train_lstm)\n",
        "\tpre_test_lstm = model_lstm.predict(x_test_lstm)\n",
        "\n",
        "\t# calculate root mean squared error\n",
        "\ttrain_rmse_lstm = math.sqrt(mean_squared_error(y_train_lstm, pre_train_lstm[:,0]))\n",
        "\tprint('train_rmse_lstm: %.2f' % (train_rmse_lstm))\n",
        "\ttest_rmse_lstm = math.sqrt(mean_squared_error(y_test_lstm, pre_test_lstm[:,0]))\n",
        "\tprint('test_rmse_lstm: %.2f' % (test_rmse_lstm))\n",
        "\treturn -test_rmse_lstm\n",
        "\n",
        "lstm_op = BayesianOptimization(\n",
        "\t\tlstm_error,\n",
        "\t\t{\n",
        "\t\t\t\t'look_back':(5),\n",
        "\t\t\t\t'first_unit':(32,256),\n",
        "\t\t\t\t'second_unit':(32,256),\n",
        "\t\t\t\t'epoch':(50,200),\n",
        "\t\t\t\t'batch_size':(1,20)\n",
        "\t\t}\n",
        ")\n",
        "\n",
        "lstm_op.maximize()\n",
        "print(lstm_op.max)\n",
        "\n",
        "#总结最优参数，为传入模型做准备\n",
        "lstm_look_back = math.floor(lstm_op.max['params']['look_back'])\n",
        "lstm_first_unit = math.floor(lstm_op.max['params']['first_unit'])\n",
        "lstm_second_unit = math.floor(lstm_op.max['params']['second_unit'])\n",
        "lstm_epoch = math.floor(lstm_op.max['params']['epoch'])\n",
        "lstm_batch_size = math.floor(lstm_op.max['params']['batch_size'])\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "np.random.seed(7)\n",
        "\n",
        "# load the dataset\n",
        "dataframe = pd.read_csv('/content/drive/jupyter/data/examples/example_wp_log_peyton_manning.csv', usecols=[1])\n",
        "# dataframe = pd.read_excel('/content/drive/jupyter/data/swat/All.xlsx', usecols=[2])\n",
        "\n",
        "dataset = dataframe.values\n",
        "dataset = dataset.astype('float32')\n",
        "\n",
        "# split into train and test sets\n",
        "train_size = int(len(dataset) * 0.8)\n",
        "test_size = len(dataset) - train_size\n",
        "train_lstm, test_lstm = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "\n",
        "# reshape into X=t and Y=t+1\n",
        "x_train_lstm, y_train_lstm = create_dataset(train_lstm, lstm_look_back)\n",
        "x_test_lstm, y_test_lstm = create_dataset(test_lstm, lstm_look_back)\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "x_train_lstm = np.reshape(x_train_lstm, (x_train_lstm.shape[0], x_train_lstm.shape[1], 1))\n",
        "x_test_lstm = np.reshape(x_test_lstm, (x_test_lstm.shape[0], x_test_lstm.shape[1], 1))\n",
        "\n",
        "# print('y_test_lstm:',y_test_lstm)\n",
        "# print('type(y_test_lstm):',type(y_test_lstm))\n",
        "\n",
        "# create and fit the LSTM network\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(LSTM(lstm_first_unit, activation='relu',return_sequences=True,input_shape=(x_train_lstm.shape[1], x_train_lstm.shape[2])))\n",
        "model_lstm.add(LSTM(lstm_second_unit, activation='relu'))\n",
        "model_lstm.add(Dense(1))\n",
        "model_lstm.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model_lstm.fit(x_train_lstm, y_train_lstm, nb_epoch=lstm_epoch, batch_size=lstm_batch_size, verbose=0)\n",
        "\n",
        "# make predictions\n",
        "pre_train_lstm = model_lstm.predict(x_train_lstm)\n",
        "pre_test_lstm = model_lstm.predict(x_test_lstm)\n",
        "\n",
        "# calculate root mean squared error\n",
        "train_rmse_lstm = math.sqrt(mean_squared_error(y_train_lstm, pre_train_lstm[:,0]))\n",
        "test_rmse_lstm = math.sqrt(mean_squared_error(y_test_lstm, pre_test_lstm[:,0]))\n",
        "print('train_rmse_lstm: %.2f' % (train_rmse_lstm))\n",
        "print('test_rmse_lstm: %.2f' % (test_rmse_lstm))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I60XSNQTBWbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########################################################  bayes-fbprophet ############################################################\n",
        "!pip install bayesian-optimization\n",
        "import pandas as pd\n",
        "from fbprophet import Prophet\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from bayes_opt import BayesianOptimization\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def fb_error(look_back,changepoint_range,changepoint_prior_scale,yearly_seasonality,holidays_prior_scale):\n",
        "  #获取数据(修改对应的列数)\n",
        "  look_back = math.floor(look_back)\n",
        "  holidays_prior_scale = math.floor(holidays_prior_scale)\n",
        "  df = pd.read_csv('/content/drive/jupyter/data/examples/example_wp_log_peyton_manning.csv')\n",
        "  # df = pd.read_excel('/content/drive/jupyter/data/swat/All.xlsx')\n",
        "  colname = df.columns.values.tolist()\n",
        "  # df = df[[colname[0],colname[2]]]\n",
        "  # df = df.rename(columns={colname[0]: \"ds\", colname[2]: \"y\"})\n",
        "  # print(len(df))\n",
        "  train_size =  int(len(df) * 0.8)\n",
        "  test_size = len(df) - train_size\n",
        "  # print(train_size,test_size)\n",
        "  fb_train = df[:train_size]\n",
        "  fb_test = df[train_size:]\n",
        "  # print(fb_train)\n",
        "  # print(fb_test)\n",
        "\n",
        "  #设置节假日\n",
        "  playoffs = pd.DataFrame({\n",
        "    'holiday': 'playoff',\n",
        "    'ds': pd.to_datetime(['2008-01-13', '2009-01-03', '2010-01-16','2010-01-24', '2010-02-07', '2011-01-08','2013-01-12', '2014-01-12', '2014-01-19',\n",
        "                          '2014-02-02', '2015-01-11', '2016-01-17','2016-01-24', '2016-02-07']),\n",
        "    'lower_window': 0,\n",
        "    'upper_window': 1,\n",
        "  })\n",
        "  superbowls = pd.DataFrame({\n",
        "    'holiday': 'superbowl',\n",
        "    'ds': pd.to_datetime(['2010-02-07', '2014-02-02', '2016-02-07']),\n",
        "    'lower_window': 0,\n",
        "    'upper_window': 1,\n",
        "  })\n",
        "  holidays = pd.concat((playoffs, superbowls))\n",
        "\n",
        "  #拟合模型\n",
        "  m = Prophet(changepoint_range=changepoint_range,\n",
        "          changepoint_prior_scale=changepoint_prior_scale,\n",
        "          yearly_seasonality=yearly_seasonality,\n",
        "          holidays_prior_scale=holidays_prior_scale)\n",
        "  m.fit(fb_train)\n",
        "\n",
        "  #设定预测长度\n",
        "  future = m.make_future_dataframe(periods = test_size)\n",
        "\n",
        "  #预测数据\n",
        "  forecast = m.predict(future)\n",
        "  forecast[['ds','yhat','yhat_lower','yhat_upper']].tail()\n",
        "\n",
        "  #展示预测效果\n",
        "  # m.plot(forecast)\n",
        "\n",
        "  pre_train_fb = forecast.yhat[look_back:train_size].values.tolist()\n",
        "  pre_test_fb = forecast.yhat[train_size+look_back:].values.tolist()\n",
        "\n",
        "  y_train_fb = df.y[look_back:train_size].values.tolist()\n",
        "  y_test_fb = df.y[train_size+look_back:].values.tolist()\n",
        "\n",
        "  fb_train_rmse = np.sqrt(mean_squared_error(pre_train_fb,y_train_fb))\n",
        "  fb_test_rmse = np.sqrt(mean_squared_error(pre_test_fb,y_test_fb))\n",
        "  print('fb_train_rmse:',fb_train_rmse)\n",
        "  print('fb_test_rmse:',fb_test_rmse)\n",
        "  return -fb_test_rmse\n",
        "\n",
        "fb_op = BayesianOptimization(\n",
        "    fb_error,\n",
        "    {\n",
        "        'look_back':(5,10),\n",
        "        'changepoint_range':(0.5,0.9),       #默认0.8\n",
        "        'changepoint_prior_scale':(0.001,0.5),   #默认0.05\n",
        "        'yearly_seasonality':(5,20),         #默认10\n",
        "        'holidays_prior_scale':(5,20)        #默认10\n",
        "    }\n",
        ")\n",
        "\n",
        "fb_op.maximize()\n",
        "print(fb_op.max)\n",
        "\n",
        "#获取数据(修改对应的列数)\n",
        "look_back = 5\n",
        "fb_look_back = math.floor(fb_op.max['params']['look_back'])\n",
        "fb_changepoint_range = fb_op.max['params']['changepoint_range']\n",
        "fb_changepoint_prior_scale = fb_op.max['params']['changepoint_prior_scale']\n",
        "fb_yearly_seasonality = fb_op.max['params']['yearly_seasonality']\n",
        "fb_holidays_prior_scale = math.floor(fb_op.max['params']['holidays_prior_scale'])\n",
        "\n",
        "df = pd.read_csv('/content/drive/jupyter/data/examples/example_wp_log_peyton_manning.csv')\n",
        "# df = pd.read_excel('/content/drive/jupyter/data/swat/All.xlsx')\n",
        "colname = df.columns.values.tolist()\n",
        "# df = df[[colname[0],colname[2]]]\n",
        "# df = df.rename(columns={colname[0]: \"ds\", colname[2]: \"y\"})\n",
        "# print(len(df))\n",
        "train_size =  int(len(df) * 0.8)\n",
        "test_size = len(df) - train_size\n",
        "# print(train_size,test_size)\n",
        "fb_train = df[:train_size]\n",
        "fb_test = df[train_size:]\n",
        "# print(fb_train)\n",
        "# print(fb_test)\n",
        "\n",
        "#设置节假日\n",
        "playoffs = pd.DataFrame({\n",
        "  'holiday': 'playoff',\n",
        "  'ds': pd.to_datetime(['2008-01-13', '2009-01-03', '2010-01-16','2010-01-24', '2010-02-07', '2011-01-08','2013-01-12', '2014-01-12', '2014-01-19',\n",
        "                        '2014-02-02', '2015-01-11', '2016-01-17','2016-01-24', '2016-02-07']),\n",
        "  'lower_window': 0,\n",
        "  'upper_window': 1,\n",
        "})\n",
        "superbowls = pd.DataFrame({\n",
        "  'holiday': 'superbowl',\n",
        "  'ds': pd.to_datetime(['2010-02-07', '2014-02-02', '2016-02-07']),\n",
        "  'lower_window': 0,\n",
        "  'upper_window': 1,\n",
        "})\n",
        "holidays = pd.concat((playoffs, superbowls))\n",
        "\n",
        "#拟合模型\n",
        "m = Prophet(changepoint_range=fb_changepoint_range,\n",
        "        changepoint_prior_scale=fb_changepoint_prior_scale,\n",
        "        yearly_seasonality=fb_yearly_seasonality,\n",
        "        holidays_prior_scale=fb_holidays_prior_scale)\n",
        "m.fit(fb_train)\n",
        "\n",
        "#设定预测长度\n",
        "future = m.make_future_dataframe(periods = test_size)\n",
        "\n",
        "#预测数据\n",
        "forecast = m.predict(future)\n",
        "forecast[['ds','yhat','yhat_lower','yhat_upper']].tail()\n",
        "\n",
        "#展示预测效果\n",
        "# m.plot(forecast)\n",
        "\n",
        "pre_train_fb = forecast.yhat[look_back:train_size].values.tolist()\n",
        "pre_test_fb = forecast.yhat[train_size+look_back:].values.tolist()\n",
        "\n",
        "y_train_fb = df.y[look_back:train_size].values.tolist()\n",
        "y_test_fb = df.y[train_size+look_back:].values.tolist()\n",
        "\n",
        "fb_train_rmse = np.sqrt(mean_squared_error(pre_train_fb,y_train_fb))\n",
        "fb_test_rmse = np.sqrt(mean_squared_error(pre_test_fb,y_test_fb))\n",
        "print('fb_train_rmse: %.2f',fb_train_rmse)\n",
        "print('fb_test_rmse: %.2f',fb_test_rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mgh3YIlXTI6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "ed5245d1-99b8-4e5b-9443-14e9c439c3db"
      },
      "source": [
        "#获取数据(修改对应的列数)\n",
        "look_back = 5\n",
        "fb_look_back = math.floor(fb_op.max['params']['look_back'])\n",
        "fb_changepoint_range = fb_op.max['params']['changepoint_range']\n",
        "fb_changepoint_prior_scale = fb_op.max['params']['changepoint_prior_scale']\n",
        "fb_yearly_seasonality = fb_op.max['params']['yearly_seasonality']\n",
        "fb_holidays_prior_scale = math.floor(fb_op.max['params']['holidays_prior_scale'])\n",
        "\n",
        "df = pd.read_csv('/content/drive/jupyter/data/examples/example_wp_log_peyton_manning.csv')\n",
        "# df = pd.read_excel('/content/drive/jupyter/data/swat/All.xlsx')\n",
        "colname = df.columns.values.tolist()\n",
        "# df = df[[colname[0],colname[2]]]\n",
        "# df = df.rename(columns={colname[0]: \"ds\", colname[2]: \"y\"})\n",
        "# print(len(df))\n",
        "train_size =  int(len(df) * 0.8)\n",
        "test_size = len(df) - train_size\n",
        "# print(train_size,test_size)\n",
        "fb_train = df[:train_size]\n",
        "fb_test = df[train_size:]\n",
        "# print(fb_train)\n",
        "# print(fb_test)\n",
        "\n",
        "#设置节假日\n",
        "playoffs = pd.DataFrame({\n",
        "  'holiday': 'playoff',\n",
        "  'ds': pd.to_datetime(['2008-01-13', '2009-01-03', '2010-01-16','2010-01-24', '2010-02-07', '2011-01-08','2013-01-12', '2014-01-12', '2014-01-19',\n",
        "                        '2014-02-02', '2015-01-11', '2016-01-17','2016-01-24', '2016-02-07']),\n",
        "  'lower_window': 0,\n",
        "  'upper_window': 1,\n",
        "})\n",
        "superbowls = pd.DataFrame({\n",
        "  'holiday': 'superbowl',\n",
        "  'ds': pd.to_datetime(['2010-02-07', '2014-02-02', '2016-02-07']),\n",
        "  'lower_window': 0,\n",
        "  'upper_window': 1,\n",
        "})\n",
        "holidays = pd.concat((playoffs, superbowls))\n",
        "\n",
        "#拟合模型\n",
        "m = Prophet(changepoint_range=fb_changepoint_range,\n",
        "        changepoint_prior_scale=fb_changepoint_prior_scale,\n",
        "        yearly_seasonality=fb_yearly_seasonality,\n",
        "        holidays_prior_scale=fb_holidays_prior_scale)\n",
        "m.fit(fb_train)\n",
        "\n",
        "#设定预测长度\n",
        "future = m.make_future_dataframe(periods = test_size)\n",
        "\n",
        "#预测数据\n",
        "forecast = m.predict(future)\n",
        "forecast[['ds','yhat','yhat_lower','yhat_upper']].tail()\n",
        "\n",
        "#展示预测效果\n",
        "# m.plot(forecast)\n",
        "\n",
        "pre_train_fb = forecast.yhat[look_back:train_size].values.tolist()\n",
        "pre_test_fb = forecast.yhat[train_size+look_back:].values.tolist()\n",
        "\n",
        "y_train_fb = df.y[look_back:train_size].values.tolist()\n",
        "y_test_fb = df.y[train_size+look_back:].values.tolist()\n",
        "\n",
        "fb_train_rmse = np.sqrt(mean_squared_error(pre_train_fb,y_train_fb))\n",
        "fb_test_rmse = np.sqrt(mean_squared_error(pre_test_fb,y_test_fb))\n",
        "print('fb_train_rmse: %.2f',fb_train_rmse)\n",
        "print('fb_test_rmse: %.2f',fb_test_rmse)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fb_train_rmse: %.2f 0.48680077659528015\n",
            "fb_test_rmse: %.2f 0.5619220762623705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsGWm0_Wzp5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################################################## ensemble-linear #############################################################################\n",
        "from sklearn import linear_model\n",
        "import numpy as np\n",
        "look_back = 5\n",
        "#首次线性回归（lstm、fbprophet模型的预测值的线性回归）\n",
        "reg1 = linear_model.LinearRegression()\n",
        "\n",
        "x_train_ensemble_linear1 = [list(t) for t in zip(pre_train_lstm,pre_train_fb)]\n",
        "x_test_ensemble_linear1 = [list(t) for t in zip(pre_test_lstm,pre_train_fb)]\n",
        "\n",
        "y_train_ensemble_linear = y_train_lstm.tolist()\n",
        "y_test_ensemble_linear = y_test_lstm.tolist()\n",
        "\n",
        "reg1.fit(x_train_ensemble_linear1,y_train_ensemble_linear)\n",
        "reg1.coef_\n",
        "\n",
        "!pip install scipy == 0.18.1\n",
        "pre_train_ensemble_linear1 = reg1.predict(x_train_ensemble_linear1)\n",
        "pre_test_ensemble_linear1 = reg1.predict(x_test_ensemble_linear1)\n",
        "\n",
        "train_ensemble_linear_rmse1 = np.sqrt(mean_squared_error(y_train_ensemble_linear,pre_train_ensemble_linear1))\n",
        "test_ensemble_linear_rmse1 = np.sqrt(mean_squared_error(y_test_ensemble_linear,pre_test_ensemble_linear1))\n",
        "\n",
        "print('train_ensemble_linear_rmse1:',train_ensemble_linear_rmse1)\n",
        "print('test_ensemble_linear_rmse1:',test_ensemble_linear_rmse1)\n",
        "\n",
        "#第二次线性回归（X、lstm、fbprophet模型的预测值的线性回归）\n",
        "x_train_lstm_ensemble,y_train_lstm = create_dataset(train_lstm,look_back)\n",
        "x_test_lstm_ensemble,y_test_lstm = create_dataset(test_lstm,look_back)\n",
        "\n",
        "x_train_ensemble_linear2 = [list(t) for t in zip(x_train_ensemble_linear1.tolist(),pre_train_ensemble_linear1)]\n",
        "x_test_ensemble_linear2 = [list(t) for t in zip(x_test_ensemble_linear1.tolist(),pre_test_ensemble_linear1)]\n",
        "\n",
        "reg2.fit(x_train_ensemble_linear2,y_train_ensemble_linear)\n",
        "reg2.coef_\n",
        "\n",
        "pre_train_ensemble_linear2 = reg2.predict(x_train_ensemble_linear2)\n",
        "pre_test_ensemble_linear2 = reg2.predict(x_test_ensemble_linear2)\n",
        "\n",
        "train_ensemble_linear_rmse2 = np.sqrt(mean_squared_error(y_train_ensemble_linear,pre_train_ensemble_linear2))\n",
        "test_ensemble_linear_rmse2 = np.sqrt(mean_squared_error(y_test_ensemble_linear,pre_test_ensemble_linear2))\n",
        "\n",
        "print('train_ensemble_linear_rmse1:',train_ensemble_linear_rmse2)\n",
        "print('test_ensemble_linear_rmse1:',test_ensemble_linear_rmse2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z1a7Na28G5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################# fb做基础 lstm做修正  ####################################################\n",
        "y_train_fb_lstm = np.array(y_train_fb) - np.array(pre_train_fb)\n",
        "y_test_fb_lstm = np.array(y_test_fb) - np.array(pre_test_fb)\n",
        "\n",
        "# 数据不归一化，数据满足预设的训练和测试长度\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "look_back = 5\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-look_back):\n",
        "\t\ta = dataset[i:(i+look_back), 0]\n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + look_back, 0])\n",
        "\treturn np.array(dataX), np.array(dataY)\n",
        "\n",
        "def fb_add_lstm_error(first_unit,second_unit,epoch,batch_size):\n",
        "  import math\n",
        "  first_unit = math.floor(first_unit)\n",
        "  second_unit = math.floor(second_unit)\n",
        "  epoch = math.floor(epoch)\n",
        "  batch_size = math.floor(batch_size)\n",
        "\n",
        "  #fix random seed for reproducibility\n",
        "  np.random.seed(7)\n",
        "\n",
        "  # load the dataset\n",
        "  dataframe = pd.read_csv('/content/drive/jupyter/data/examples/example_wp_log_peyton_manning.csv', usecols=[1])\n",
        "  # dataframe = pd.read_excel('/content/drive/jupyter/data/swat/All.xlsx', usecols=[2])\n",
        "\n",
        "  dataset = dataframe.values\n",
        "  dataset = dataset.astype('float32')\n",
        "\n",
        "  # split into train and test sets\n",
        "  train_size = int(len(dataset) * 0.8)\n",
        "  test_size = len(dataset) - train_size\n",
        "  train_lstm, test_lstm = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "\n",
        "  # reshape into X=t and Y=t+1\n",
        "  x_train_lstm, y_train_lstm = create_dataset(train_lstm, look_back)\n",
        "  x_test_lstm, y_test_lstm = create_dataset(test_lstm, look_back)\n",
        "\n",
        "  # reshape input to be [samples, time steps, features]\n",
        "  x_train_lstm = np.reshape(x_train_lstm, (x_train_lstm.shape[0], x_train_lstm.shape[1], 1))\n",
        "  x_test_lstm = np.reshape(x_test_lstm, (x_test_lstm.shape[0], x_test_lstm.shape[1], 1))\n",
        "\n",
        "  # print('y_test_lstm:',y_test_lstm)\n",
        "  # print('type(y_test_lstm):',type(y_test_lstm))\n",
        "\n",
        "  # create and fit the LSTM network\n",
        "  model_lstm = Sequential()\n",
        "  model_lstm.add(LSTM(first_unit, activation='relu',return_sequences=True,input_shape=(x_train_lstm.shape[1], x_train_lstm.shape[2])))\n",
        "  model_lstm.add(LSTM(second_unit, activation='relu'))\n",
        "  model_lstm.add(Dense(1))\n",
        "  model_lstm.compile(loss='mean_squared_error', optimizer='adam')\n",
        "  model_lstm.fit(x_train_lstm, y_train_fb_lstm, nb_epoch=epoch, batch_size=batch_size, verbose=2)\n",
        "\n",
        "  # make predictions\n",
        "  pre_train_lstm = model_lstm.predict(x_train_lstm)\n",
        "  pre_test_lstm = model_lstm.predict(x_test_lstm)\n",
        "\n",
        "  ######################## 以下变量均为1维（pre_test_lstm为2维，进行了降维处理）  #############################\n",
        "  train_fb_add_lstm = pre_train_fb + pre_train_lstm\n",
        "  test_fb_add_lstm = pre_test_fb + pre_test_lstm.flatten()\n",
        "  train_rmse_fb_add_lstm = np.sqrt(mean_squared_error(train_fb_add_lstm,y_train_fb))\n",
        "  test_rmse_fb_add_lstm = np.sqrt(mean_squared_error(test_fb_add_lstm,y_test_fb))\n",
        "  print('train_rmse_fb_add_lstm:',train_rmse_fb_add_lstm)\n",
        "  print('test_rmse_fb_add_lstm:',test_rmse_fb_add_lstm)\n",
        "  return -test_rmse_fb_add_lstm\n",
        "\n",
        "fb_add_lstm_op = BayesianOptimization(\n",
        "    fb_add_lstm_op_error,\n",
        "    {\n",
        "        'first_unit':(32,256),\n",
        "        'second_unit':(32,256),\n",
        "        'epoch':(50,200),\n",
        "        'batch_size':(1,20)\n",
        "    }\n",
        ")\n",
        "fb_add_lstm_op.maximize()\n",
        "print(fb_add_lstm_op.max)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFkorpfvZyAv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "87f21a69-ed37-451a-9f21-9e7fe525695a"
      },
      "source": [
        "################################################################# fb做基础 cnn-lstm做修正  ####################################################\n",
        "y_train_fb_add_cnn_lstm = np.array(y_train_fb) - np.array(pre_train_fb)\n",
        "y_test_fb_add_cnn_lstm = np.array(y_test_fb) - np.array(pre_test_fb)\n",
        "\n",
        "# 数据不归一化，数据满足预设的训练和测试长度\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM,Flatten,TimeDistributed\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.layers.convolutional import Con1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "\n",
        "look_back = 5\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-look_back):\n",
        "\t\ta = dataset[i:(i+look_back), 0]\n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + look_back, 0])\n",
        "\treturn np.array(dataX), np.array(dataY)\n",
        "\n",
        "def fb_add_cnn_lstm(filters,unit,epochs,batch_size): \n",
        "  import math\n",
        "  filters = math.floor(filters)\n",
        "  unit = math.floor(unit)\n",
        "  epochs = math.floor(epochs)\n",
        "  batch_size = math.floor(batch_size)\n",
        "\n",
        "  #fix random seed for reproducibility\n",
        "  np.random.seed(7)\n",
        "\n",
        "  # load the dataset\n",
        "  dataframe = pd.read_csv('/content/drive/jupyter/data/examples/example_wp_log_peyton_manning.csv', usecols=[1])\n",
        "  # dataframe = pd.read_excel('/content/drive/jupyter/data/swat/All.xlsx', usecols=[2])\n",
        "\n",
        "  dataset = dataframe.values\n",
        "  dataset = dataset.astype('float32')\n",
        "\n",
        "  # split into train and test sets\n",
        "  train_size = int(len(dataset) * 0.8)\n",
        "  test_size = len(dataset) - train_size\n",
        "  train_lstm, test_lstm = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "\n",
        "  # reshape into X=t and Y=t+1\n",
        "  x_train_fbcnnlstm, y_train_fbcnnlstm = create_dataset(train_lstm, look_back)\n",
        "  x_test_fbcnnlstm, y_test_fbcnnlstm = create_dataset(test_lstm, look_back)\n",
        "\n",
        "  # reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
        "  n_features = 1\n",
        "  n_seq = 1\n",
        "  n_steps = 5\n",
        "  x_train_fbcnnlstm = x_train_fbcnnlstm.reshape((x_train_fbcnnlstm.shape[0], n_seq, n_steps, n_features))\n",
        "  x_test_fbcnnlstm = x_test_fbcnnlstm.reshape((x_test_fbcnnlstm.shape[0], n_seq, n_steps, n_features))\n",
        "\n",
        "  # print('y_test_lstm:',y_test_lstm)\n",
        "  # print('type(y_test_lstm):',type(y_test_lstm))\n",
        "\n",
        "  # create and fit the LSTM network\n",
        "  model_fbcnnlstm = Sequential()\n",
        "  model_fbcnnlstm.add(TimeDistributed(Conv1D(filters=filters, kernel_size=1, activation='relu'), input_shape=(None, n_steps, n_features)))\n",
        "  model_fbcnnlstm.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
        "  model_fbcnnlstm.add(TimeDistributed(Flatten()))\n",
        "  model_fbcnnlstm.add(LSTM(unit, activation='relu'))\n",
        "  model_fbcnnlstm.add(Dense(1))\n",
        "  model_fbcnnlstm.compile(optimizer='adam', loss='mse')\n",
        "  model_fbcnnlstm.fit(x_train_cnnlstm,y_train_cnnlstm,epochs=epochs,batch_size=batch_size,verbose = 2)\n",
        "\n",
        "  # make predictions\n",
        "  pre_train_fbcnnlstm = model_fbcnnlstm.predict(x_train_fbcnnlstm)\n",
        "  pre_test_fbcnnlstm = model_fbcnnlstm.predict(x_test_fbcnnlstm)\n",
        "\n",
        "  ######################## 以下变量均为1维（pre_test_lstm为2维，进行了降维处理）  #############################\n",
        "  train_fb_add_cnn_lstm = pre_train_fb + pre_train_fbcnnlstm\n",
        "  test_fb_add_cnn_lstm = pre_test_fb + pre_test_fbcnnlstm.flatten()\n",
        "  train_rmse_fb_add_cnn_lstm = np.sqrt(mean_squared_error(train_fb_add_cnn_lstm,y_train_fb))\n",
        "  test_rmse_fb_add_cnn_lstm = np.sqrt(mean_squared_error(test_fb_add_cnn_lstm,y_test_fb))\n",
        "  print('train_rmse_fb_add_cnn_lstm:',train_rmse_fb_add_cnn_lstm)\n",
        "  print('test_rmse_fb_add_cnn_lstm:',test_rmse_fb_add_cnn_lstm)\n",
        "  return -test_rmse_fb_add_cnn_lstm\n",
        "\n",
        "fb_add_cnn_lstm_op = BayesianOptimization(\n",
        "    fb_add_cnn_lstm_error,\n",
        "    {\n",
        "        'filters':(16,128),\n",
        "        'unit':(32,128),\n",
        "        'epochs':(50,500),\n",
        "        'batch_size':(1,10)\n",
        "    }\n",
        ")\n",
        "fb_add_cnn_lstm_op.maximize()\n",
        "print(fb_add_cnn_lstm.max)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:60: UserWarning:\n",
            "\n",
            "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            " - 9s - loss: 0.2372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYuYNOd4Ch6y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "ef52f79e-5149-4e8e-804b-0a3b6008ebfe"
      },
      "source": [
        "################################################################################### bayes-cnn ###########################################################################\n",
        "# convert an array of values into a dataset matrix\n",
        "import numpy as np\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import pandas as pd\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import MaxPooling1D\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "!pip install bayesian-optimization\n",
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "def create_dataset(dataset, look_back):\n",
        "  dataX, dataY = [], []\n",
        "  look_back = math.floor(look_back)\n",
        "  # print(look_back)\n",
        "  for i in range(len(dataset)-look_back):\n",
        "    a = dataset[i:i+look_back, 0]\n",
        "    dataX.append(a)\n",
        "    dataY.append(dataset[i + look_back, 0])\n",
        "  return numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "def cnn_error(look_back,unit,epoch):\n",
        "  look_back = math.floor(look_back)\n",
        "  unit = math.floor(unit)\n",
        "  epoch = math.floor(epoch)\n",
        "  batch_size = math.floor(batch_size) \n",
        "\n",
        "  dataframe = pandas.read_csv('example_wp_log_peyton_manning.csv', usecols=[1])\n",
        "  # dataframe = pandas.read_excel('/content/drive/jupyter/data/swat/All.xlsx', usecols=[2])\n",
        "  dataset = dataframe.values\n",
        "  dataset = dataset.astype('float32')\n",
        "  \n",
        "  # split into train and test sets\n",
        "  train_size = int(len(dataset) * 0.8)\n",
        "  test_size = len(dataset) - train_size\n",
        "  train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "\n",
        "  # reshape into X=t and Y=t+1\n",
        "  x_train_cnn, y_train_cnn = create_dataset(train, look_back)\n",
        "  x_test_cnn, y_test_cnn = create_dataset(test, look_back)\n",
        "\n",
        "  n_features = 1\n",
        "  x_train_cnn_model = x_train_cnn.reshape((x_train_cnn.shape[0], x_train_cnn.shape[1], n_features))\n",
        "\n",
        "  # define model\n",
        "  model = Sequential()\n",
        "  model.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(int(look_back), n_features)))\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(unit, activation='relu'))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(optimizer='adam', loss='mse')\n",
        "  # fit model\n",
        "  model.fit(x_train_cnn_model, y_train_cnn, epochs=epoch, verbose=0)\n",
        "  # demonstrate prediction\n",
        "  # x_input = array([70, 80, 90])\n",
        "  x_test_cnn_model = x_test_cnn.reshape((len(x_test_cnn), int(look_back), n_features))\n",
        "  pre_train_cnn = model.predict(x_train_cnn_model,verbose=0)\n",
        "  pre_test_cnn = model.predict(x_test_cnn_model, verbose=0)\n",
        "\n",
        "  from sklearn.metrics import mean_squared_error\n",
        "  train_rmse_cnn = np.sqrt(mean_squared_error(pre_train_cnn,y_train_cnn))\n",
        "  test_rmse_cnn = np.sqrt(mean_squared_error(pre_test_cnn,y_test_cnn))\n",
        "  print('train_rmse_cnn:',train_rmse_cnn)\n",
        "  print('test_rmse_cnn:',test_rmse_cnn)\n",
        "  return -test_rmse_cnn\n",
        "\n",
        "#以下的四个属性，是参数的变化范围，你可以自己设定\n",
        "cnn_op = BayesianOptimization(\n",
        "        cnn_error,\n",
        "        pbounds={\n",
        "         'look_back': (5),\n",
        "         'unit': (16,256),\n",
        "         'epoch': (50,200)\n",
        "         }\n",
        "    )\n",
        "\n",
        "opt.maximize()\n",
        "print(cnn_op.max)\n",
        "\n",
        "#提取最优参数\n",
        "cnn_look_back = math.floor(cnn_op.max['params']['look_back'])\n",
        "cnn_unit = math.floor(cnn_op.max['params']['unit'])\n",
        "cnn_epoch = math.floor(cnn_op.max['params']['epoch'])\n",
        "\n",
        "dataframe = pandas.read_csv('example_wp_log_peyton_manning.csv', usecols=[1])\n",
        "# dataframe = pandas.read_excel('/content/drive/jupyter/data/swat/All.xlsx', usecols=[2])\n",
        "dataset = dataframe.values\n",
        "dataset = dataset.astype('float32')\n",
        "\n",
        "# split into train and test sets\n",
        "train_size = int(len(dataset) * 0.8)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "\n",
        "# reshape into X=t and Y=t+1\n",
        "x_train_cnn, y_train_cnn = create_dataset(train, look_back)\n",
        "x_test_cnn, y_test_cnn = create_dataset(test, look_back)\n",
        "\n",
        "n_features = 1\n",
        "x_train_cnn_model = x_train_cnn.reshape((x_train_cnn.shape[0], x_train_cnn.shape[1], n_features))\n",
        "\n",
        "# define model\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(int(look_back), n_features)))\n",
        "cnn_model.add(MaxPooling1D(pool_size=2))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(unit, activation='relu'))\n",
        "cnn_model.add(Dense(1))\n",
        "cnn_model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "cnn_model.fit(x_train_cnn_model, y_train_cnn, epochs=epoch, verbose=0)\n",
        "# demonstrate prediction\n",
        "# x_input = array([70, 80, 90])\n",
        "x_test_cnn_model = x_test_cnn.reshape((len(x_test_cnn), int(look_back), n_features))\n",
        "pre_train_cnn = model.predict(x_train_cnn_model,verbose=0)\n",
        "pre_test_cnn = model.predict(x_test_cnn_model, verbose=0)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "train_rmse_cnn = np.sqrt(mean_squared_error(pre_train_cnn,y_train_cnn))\n",
        "test_rmse_cnn = np.sqrt(mean_squared_error(pre_test_cnn,y_test_cnn))\n",
        "print('train_rmse_cnn:',train_rmse_cnn)\n",
        "print('test_rmse_cnn:',test_rmse_cnn)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'target': -0.5427652714890532, 'params': {'changepoint_prior_scale': 0.10560102522562856, 'changepoint_range': 0.6567488216185153, 'holidays_prior_scale': 12.024153026998672, 'look_back': 4.955915494507302, 'yearly_seasonality': 16.00396642268028}}\n",
            "<class 'dict'>\n",
            "-0.5427652714890532\n",
            "4.955915494507302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R9DdU4ED78w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}